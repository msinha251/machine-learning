{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-26 08:50:04.831917: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Build image classifier for dino-dragon dataset\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1436 images belonging to 2 classes.\n",
      "Found 158 images belonging to 2 classes.\n",
      "Epoch 1/10\n",
      " 45/100 [============>.................] - ETA: 24s - loss: 0.5632 - accuracy: 0.7096WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 1000 batches). You may need to use the repeat() function when building your dataset.\n",
      "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 50 batches). You may need to use the repeat() function when building your dataset.\n",
      "100/100 [==============================] - 22s 210ms/step - loss: 0.5632 - accuracy: 0.7096 - val_loss: 0.3839 - val_accuracy: 0.8987 - lr: 1.0000e-04\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "train_datagen = ImageDataGenerator(rescale=1./255, validation_split=0.1)\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "                                                    'data/dino-dragon/train/',\n",
    "                                                    target_size=(150, 150),\n",
    "                                                    batch_size=32,\n",
    "                                                    class_mode='binary',\n",
    "                                                    subset='training'\n",
    "                                                    )\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "                                                    'data/dino-dragon/train/',\n",
    "                                                    target_size=(150, 150),\n",
    "                                                    batch_size=32,\n",
    "                                                    class_mode='binary',\n",
    "                                                    subset='validation'\n",
    "                                                    )\n",
    "\n",
    "# build model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "                optimizer=Adam(learning_rate=0.0001),\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "steps_per_epoch = train_generator.n // train_generator.batch_size\n",
    "\n",
    "# train model\n",
    "history = model.fit(\n",
    "                    train_generator,\n",
    "                    steps_per_epoch=steps_per_epoch,\n",
    "                    epochs=10,\n",
    "                    validation_data=validation_generator,\n",
    "                    validation_steps=50,\n",
    "                    callbacks=[\n",
    "                                EarlyStopping(monitor='val_loss', patience=5),\n",
    "                                ReduceLROnPlateau(monitor='val_loss', patience=3)\n",
    "                                ]\n",
    "                    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "bade87d67844cc7ba434e1b3fd800a2810b320c8b04d769557ea0aad6f0ea527"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
